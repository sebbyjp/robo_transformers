{
    "summary": "This code uses TensorFlow and PyTorch for machine learning, downloads checkpoints from a URL registry, and applies the Universal Sentence Encoder. It includes functions for image processing during model inference and defines a function to measure rotation delta and gripper closedness. The \"robo_transformers\" project's inference.py file also supports custom instructions via \"--instruction\".",
    "details": [
        {
            "comment": "The code imports necessary libraries and defines a registry of URLs for downloadable models. The codebase seems to involve machine learning or image processing tasks, using TensorFlow, PyTorch, and related packages. These models may be used for various tasks like object detection, classification, or prediction in different contexts such as robotics or research.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":0-24",
            "content": "import tensorflow as tf\nimport numpy as np\nimport PIL.Image as Image\nimport tensorflow_hub as hub\nfrom tf_agents.policies.py_tf_eager_policy import (\n    SavedModelPyTFEagerPolicy as LoadedPolicy,\n)\nfrom tf_agents.trajectories import time_step as ts, policy_step as ps\nfrom tf_agents import specs\nfrom tf_agents.typing import types\nfrom importlib.resources import files\nfrom absl import logging, flags, app\nimport os\nimport gdown\nimport sys\nfrom pprint import pprint\nfrom typing import Optional\nREGISTRY = {\n    \"rt1main\": \"https://drive.google.com/drive/folders/1QG99Pidaw6L9XYv1qSmuip_qga9FRcEC?usp=drive_link\",\n    \"rt1simreal\": \"https://drive.google.com/drive/folders/1_nudHVmGuGUpGcrLlswg9O-aWy27Cjg0?usp=drive_link\",\n    \"rt1multirobot\": \"https://drive.google.com/drive/folders/1EWjKSnfvD-ANPTLxugpCVP5zU6ADy8km?usp=drive_link\",\n    \"rt1x\": \"https://drive.google.com/drive/folders/1LjTizUsqM88-5uHAIczTrObB3_z4OlgE?usp=drive_link\",\n    # 'xgresearch':\n    #     \"https://drive.google.com/drive/folders/185nP-a8z-1Pm6Zc3yU2qZ01hoszyYx51?usp=drive_link\""
        },
        {
            "comment": "The code defines command line flags for instruction, model key, checkpoint path and show option. It also defines a WIDTH and HEIGHT variables. The class LazyTFModule lazy loads a TensorFlow module and TEXT_ENCODER is an instance of this class which loads the Universal Sentence Encoder from TF Hub. There's also a function to download checkpoint specified by key or output file name.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":25-69",
            "content": "}\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\n    \"instruction\", \"pick up the block\", \"The instruction to run inference on.\"\n)\nflags.DEFINE_string(\n    \"model_key\",\n    \"rt1simreal\",\n    \"Which model to load. Must be one of: \" + str(REGISTRY.keys()),\n)\nflags.DEFINE_string(\n    \"checkpoint_path\", None, \"Custom checkpoint path. This overrides the model key.\"\n)\nflags.DEFINE_boolean(\"show\", False, \"Whether or not to show the demo images.\")\nWIDTH = 320\nHEIGHT = 256\nclass LazyTFModule:\n    \"\"\"Lazy loads a tensorflow module.\"\"\"\n    def __init__(self, url: str):\n        self.url = url\n        self.module = None\n    def __getattr__(self, name: str):\n        if self.module is None:\n            self.module = hub.load(self.url)\n        return getattr(self.module, name)\n    def __call__(self, *args, **kwargs):\n        if self.module is None:\n            self.module = hub.load(self.url)\n        return self.module(*args, **kwargs)\nTEXT_ENCODER = LazyTFModule(\n    \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n)\ndef download_checkpoint(key: str, output: str = None):"
        },
        {
            "comment": "This code defines a function `load_rt1` that loads a trained RT-1 model from a checkpoint. It takes arguments for the model key, custom checkpoint path, whether to load from the .pb file in the checkpoint directory, whether to use tf functions, and whether to batch time steps. If the specified output path doesn't exist, it downloads the new model before loading it.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":70-100",
            "content": "    if key not in REGISTRY.keys():\n        logging.fatal(\"Invalid model key. Must be one of: \", REGISTRY.keys())\n    if output is None:\n        downloads_folder = os.path.join(os.getcwd(), \"checkpoints/rt1/\")\n    else:\n        downloads_folder = output\n    output = os.path.join(downloads_folder, key)\n    if not os.path.exists(output):\n        logging.info(\"Downloading new model: \", key)\n        gdown.download_folder(\n            REGISTRY[key], output=downloads_folder, quiet=True, use_cookies=False\n        )\n    return output\ndef load_rt1(\n    model_key: str = \"rt1simreal\",\n    checkpoint_path: str = None,\n    load_specs_from_pbtxt: bool = True,\n    use_tf_function: bool = True,\n    batch_time_steps: bool = False,\n    downloads_folder: bool = None,\n) -> LoadedPolicy:\n    \"\"\"Loads a trained RT-1 model from a checkpoint.\n    Args:\n        model_key (str, optional):  Model to load.\n        checkpoint_path (str, optional): Custom checkpoint path.\n        load_specs_from_pbtxt (bool, optional): Load from the .pb file in the checkpoint dir. Defaults to True."
        },
        {
            "comment": "This function is for loading and returning a tf_agents policy object from the given checkpoint path. It also handles downloading the checkpoint if no path is provided, sets the logging verbosity level to suppress certain warnings, and allows optional parameters for tf_function wrapping and batch time steps handling during inference. The embed_text function converts a text input into a tensor, with an option to specify batch size.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":101-129",
            "content": "        use_tf_function (bool, optional): Wraps function with optimized tf.Function to speed up inference. Defaults to True.\n        batch_time_steps (bool, optional): Whether to automatically add a batch dimension during inference. Defaults to False.\n    Returns:\n        tf_agents.polices.tf_policy.TFPolicy: A tf_agents policy object.\n    \"\"\"\n    # Suppress warnings from gdown and tensorflow.\n    log_level = logging.get_verbosity()\n    if log_level < 2:\n        logging.set_verbosity(logging.ERROR)\n    if checkpoint_path is None:\n        checkpoint_path = download_checkpoint(model_key, downloads_folder)\n    print(\"Loading RT-1 from checkpoint: {}...\".format(checkpoint_path))\n    policy: LoadedPolicy = LoadedPolicy(\n        model_path=checkpoint_path,\n        load_specs_from_pbtxt=load_specs_from_pbtxt,\n        use_tf_function=use_tf_function,\n        batch_time_steps=batch_time_steps,\n    )\n    print(\"RT-1 loaded.\")\n    logging.set_verbosity(log_level)\n    return policy\ndef embed_text(input: list[str] | str, batch_size: int = 1) -> tf.Tensor:"
        },
        {
            "comment": "This code snippet contains two functions: \"embed_string\" and \"format_images\". The first function takes a string input, embeds it using the Universal Sentence Encoder, and returns a tensor of shape (batch\\_size, 512). The second function formats a list of images to the correct shape and type, returning a tensor of shape (batch\\_size, HEIGHT, WIDTH, 3).",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":130-162",
            "content": "    \"\"\"Embeds a string using the Universal Sentence Encoder. Copies the string\n        to fill the batch dimension.\n    Args:\n        input (str): The string to embed.\n        batch_size (int, optional): . Defaults to 1.\n    Returns:\n        tf.Tensor: A tensor of shape (batch_size, 512).\n    \"\"\"\n    if isinstance(input, str):\n        input = input.lstrip(' ').rstrip(' ')\n        input = np.tile(np.array(input), (batch_size,))\n    embedded = TEXT_ENCODER(input).numpy()[0]\n    return tf.reshape(\n        tf.convert_to_tensor(embedded, dtype=tf.float32), (batch_size, 512)\n    )\ndef format_images(images: np.ndarray | list[np.ndarray]) -> tf.Tensor:\n    \"\"\"Formats a list of images to the correct shape and type.\n    Args:\n        images (np.ndarray | list[np.ndarray]): Must have at most 4 dimensions.\n    Returns:\n        tf.Tensor: A tensor of shape (batch_size, HEIGHT, WIDTH, 3).\n    \"\"\"\n    if isinstance(images, np.ndarray) and len(images.shape) == 3:\n        images = np.expand_dims(images, axis=0)\n    out = []\n    for image in images:"
        },
        {
            "comment": "This code snippet is from the `inference` function in the RoboTransformers library. It takes a list of images and instructions as input, and performs image processing and inference using a loaded policy model. The image processing involves converting the image to a tensor, resizing it with padding to a target width and height, reshaping the image tensor, casting the image tensor back to uint8 type, and appending it to a list of images. Finally, it returns the concatenated list of images using tf.concat. The inference function also takes optional arguments such as reward, policy, policy_state, and terminate, which can be used for additional processing or control flow within the function.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":163-189",
            "content": "        image = tf.convert_to_tensor(image, dtype=tf.uint8)\n        image = tf.image.resize_with_pad(\n            image, target_width=WIDTH, target_height=HEIGHT\n        )\n        image = tf.reshape(image, (1, HEIGHT, WIDTH, 3))\n        image = tf.cast(image, dtype=tf.uint8)\n        out.append(image)\n    return tf.concat(out, 0)\ndef inference(\n    instructions: list[str] | str,\n    imgs: list[np.ndarray] | np.ndarray,\n    step: int,\n    reward: Optional[list[float] | float] = None,\n    policy: Optional[LoadedPolicy] = None,\n    policy_state=Optional[types.NestedArray],\n    terminate=False,\n) -> tuple[ps.ActionType, types.NestedSpecTensorOrArray, types.NestedSpecTensorOrArray]:\n    \"\"\"Runs inference on a list of images and instructions.\n    Args:\n        instructions (list[str]): A list of instructions. E.g. [\"pick up the block\"]\n        imgs (list[np.ndarray]): A list of images with shape[(HEIGHT, WIDTH, 3)]\n        step (int): The current time step.\n        reward (list[float], optional): Defaults to None.\n        policy (tf_agents.policies.tf_policy.TFPolicy, optional): Defaults to None."
        },
        {
            "comment": "This code is loading the RT-1 policy, calculating batch size based on instructions, creating an observation for RT-1 to read and setting default reward values if necessary. The output is a tuple containing action, state, and info from the policy following the \"Data Types\" section in README.md.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":190-216",
            "content": "        state (, optional). The internal network state. See 'policy state' in the \"Data Types\" section\n            of README.md. Defaults to None.\n        terminate (bool, optional): Whether or not to terminate the episode. Defaults to False.\n    Returns:\n        tuple[Action, State, Info]: The action, state, and info from the policy Again see the\n         \"Data Types\" section of README.md.\n    \"\"\"\n    if policy is None:\n        policy = load_rt1()\n    # Calculate batch size from instructions shape.\n    if isinstance(instructions, str):\n        batch_size = 1\n        if reward is not None:\n            reward = reward * np.ones((batch_size,), dtype=np.float32)\n    else:\n        batch_size = len(instructions)\n    # Create the observation. RT-1 only reads the 'image' and 'natural_language_embedding' keys\n    # so everything else can be zero.\n    observation = specs.zero_spec_nest(\n        specs.from_spec(policy.time_step_spec.observation), outer_dims=(batch_size,)\n    )\n    if reward is None:\n        reward = np.zeros((batch_size,), dtype=np.float32)"
        },
        {
            "comment": "This code initializes the policy state if none is given, prepares time step, and obtains action, next state, and info from the policy. If logging is enabled at debug level, it writes a scalar for \"world_vector\" in three iterations to a file writer.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":218-243",
            "content": "    if policy_state is None:\n         # Run dummy inference to get the initial state.\n        policy_state = policy.get_initial_state(batch_size)\n        time_step = ts.transition(observation, np.zeros((batch_size,), dtype=np.float32))\n        _, policy_state, _ = policy.action(time_step, policy_state)\n    observation[\"image\"] = format_images(imgs)\n    observation['natural_language_embedding'] = embed_text(\n        instructions, batch_size)\n    if step == 0:\n        time_step = ts.restart(observation, batch_size)\n    elif terminate:\n        time_step = ts.termination(observation, reward)\n    else:\n        time_step = ts.transition(observation, reward)\n    action, next_state, info = policy.action(time_step, policy_state)\n    if logging.level_debug():\n        writer = tf.summary.create_file_writer(\"./runs\")\n        with writer.as_default():\n            for i in range(3):\n                tf.summary.scalar(\n                    \"world_vector{}\".format(i), action[\"world_vector\"][0, i], step=step\n                )"
        },
        {
            "comment": "This code snippet is from the \"robo_transformers\" project, specifically in the models/rt1/inference.py file. The function defines a method that measures rotation delta and gripper closedness for each action step and writes these as summaries for later use. It returns the action, next state, and additional information. There's also a separate function, get_demo_images(), which loads a demo video from a specified directory into tensors of shape (batch_size, HEIGHT, WIDTH, 3). It suppresses noisy PIL warnings to improve performance.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":244-273",
            "content": "                tf.summary.scalar(\n                    \"rotation_delta{}\".format(i),\n                    action[\"rotation_delta\"][0, i],\n                    step=step,\n                )\n            tf.summary.scalar(\n                \"gripper_closedness_action{}\".format(i),\n                action[\"gripper_closedness_action\"][0, 0],\n                step=step,\n            )\n            writer.flush()\n    return action, next_state, info\ndef get_demo_images(output=None) -> np.ndarray:\n    \"\"\"Loads a demo video from the directory.\n    Returns:\n        list[tf.Tensor]: A list of tensors of shape (batch_size, HEIGHT, WIDTH, 3).\n    \"\"\"\n    # Suppress noisy PIL warnings.\n    log_level = logging.get_verbosity()\n    if logging.get_verbosity() < 2:\n        logging.set_verbosity(logging.ERROR)\n    filenames = [\n        files(\"robo_transformers\").joinpath(\"demo_imgs/gripper_far_from_grasp.png\"),\n        files(\"robo_transformers\").joinpath(\"demo_imgs/gripper_mid_to_grasp.png\"),\n        files(\"robo_transformers\").joinpath(\"demo_imgs/gripper_almost_grasp.png\"),"
        },
        {
            "comment": "The code defines a function `run_demo` that loads a policy and executes a demo for three images. It first checks if a policy is provided, if not it loads the policy from FLAGS.model_key and FLAGS.checkpoint_path. Then, it retrieves the images by calling `get_demo_images`, sets rewards as [0, 0, 0], and initializes the state as None. For each step in a range of 3, it performs inference on the image, prints the action taken, and updates the state if necessary. If the step is the last one (step == 2), it terminates the demo. The code also logs messages based on the verbosity level set by FLAGS. Finally, it enables debugging information if logging is set to debug level.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":274-312",
            "content": "    ]\n    images = []\n    for fn in filenames:\n        img = Image.open(fn)\n        if FLAGS.show and output is not None:\n            img.save(os.path.join(output, fn.name))\n        img = np.array(img.convert(\"RGB\"))\n        images.append(img)\n    logging.set_verbosity(log_level)\n    return images\ndef run_demo(policy: LoadedPolicy = None):\n    if policy is None:\n        policy = load_rt1(FLAGS.model_key, FLAGS.checkpoint_path)\n    # Pass in an instruction through the --instructions flag.\n    # The rewards will not affect the inference at test time.\n    images = get_demo_images(output=os.getcwd())\n    rewards = [0, 0, 0]\n    state = None\n    for step in range(3):\n        action, state, _ = inference(\n            FLAGS.instruction,\n            images[step],\n            step,\n            rewards[step],\n            policy,\n            policy_state=state,\n            terminate=(step == 2),\n        )\n        pprint(action)\n        print(\" \")\ndef main(_):\n    if logging.level_debug():\n        tf.debugging.experimental.enable_dump_debug_info("
        },
        {
            "comment": "This code snippet is a part of the RT-1 inference demo. It uses pretrained Universal Sentence Encoder and ViT models to run inference on three images from the \"demo_imgs\" directory, displaying the output on the console. A custom instruction can be passed via the \"--instruction\" flag. The code is designed to be executed as a standalone script.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":313-342",
            "content": "            \"./runs\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1\n        )\n    # Run three time steps of inference using the demo images.\n    # Pass in an instruction via the command line.\n    run_demo()\nif __name__ == \"__main__\":\n    if \"--help\" in sys.argv or \"-h\" in sys.argv:\n        print(\n            \"\"\"\n        RT-1 Inference Demo\n        -------------------\n        This demo runs inference on a pretrained RT-1 model. It uses a pretrained\n        Universal Sentence Encoder to embed the instruction and a pretrained\n        ViT to extract features from the image.\n        The demo will run inference on three images from the demo_imgs directory\n        and print the output to the console.\n        You can also pass in a custom instruction via the --instruction flag.\n        To run the demo, use the following command:\n        python3 -m robo_transformers.rt1.inference --model_key=rt1simreal --instruction=\"pick block\"\n        \"\"\"\n        )\n    app.run(main)\nelse:\n    # TODO (speralta): Consider reading in flags from argv"
        },
        {
            "comment": "This code reads in the program name from command line arguments. It sets flags for an application using the FLAGS function, but be cautious as it may crash if unrecognized flags are provided. This setup is tailored to applications that use app.run().",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/rt1/inference.py\":343-347",
            "content": "    # CAREFUL: This will crash if you allow flags from argv that haven't been\n    # defined.\n    # For now, only apps that use app.run() can set flags.\n    # Read in the program name\n    FLAGS(sys.argv[0:1])"
        }
    ]
}