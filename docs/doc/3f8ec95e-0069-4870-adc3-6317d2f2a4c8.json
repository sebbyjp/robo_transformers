{
    "summary": "The OctoAgent class inherits from Agent, initializes an OctoModel and two lists. The act method processes inputs, creates tasks, samples normalized actions, populates image history, and returns a RT1Action using calculated normalized action.",
    "details": [
        {
            "comment": "The code defines a class called `OctoAgent` that inherits from the `Agent` abstract class. It initializes an instance of the `OctoModel` and two lists to store image history and wrist images, both in chronological order. The `act` method takes an instruction, image, and optional image_wrist as input, and returns a `RT1Action`. The code also resizes the input image and removes old elements from the image history if the window size is exceeded.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/octo/agent.py\":0-26",
            "content": "from robo_transformers.abstract.agent import Agent\nfrom robo_transformers.models.octo.action import OctoAction\nfrom robo_transformers.models.rt1.action import RT1Action\nfrom typing import Optional\nimport jax\nimport os\nimport cv2\nimport numpy as np\nimport numpy.typing as npt\nfrom octo.model.octo_model import OctoModel\nfrom beartype import beartype\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n@beartype\nclass OctoAgent(Agent):\n    def __init__(self, weights_key: str = 'octo-small', window_size: int = 2) -> None:\n        self.model: OctoModel = OctoModel.load_pretrained(\"hf://rail-berkeley/\" + weights_key)\n        self.image_history = [] # Chronological order.\n        self.image_wrist_history = [] # Chronological order.    \n        self.window_size = window_size\n    def act(self, instruction: str, image: npt.ArrayLike, image_wrist: Optional[npt.ArrayLike] = None) -> RT1Action:\n        image = cv2.resize(np.array(image, dtype=np.uint8), (256, 256))\n        self.image_history.append(image)\n        if len(self.image_history) > self.window_size:"
        },
        {
            "comment": "Code snippet populates the image history and wrist image history, normalizes actions using model statistics and stores them in 'norm_actions'. The 'observation' dictionary includes primary image and pad mask. If wrist image is not None, it resizes, appends to history and adds wrist image to observation. 'model.create_tasks()' creates tasks from input instruction and 'model.sample_actions()' samples normalized actions for given observation and task.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/octo/agent.py\":27-47",
            "content": "            self.image_history.pop(0)\n        images = np.stack(self.image_history)[None]\n        np.expand_dims(images, axis=0)\n        observation = {\"image_primary\": images, \"pad_mask\": np.full((1, images.shape[1]), True, dtype=bool)}\n        if image_wrist is not None:\n            image_wrist = cv2.resize(np.array(image_wrist, dtype=np.uint8), (128, 128))\n            self.image_wrist_history.append(image_wrist)\n            if len(self.image_wrist_history) > self.window_size:\n                self.image_wrist_history.pop(0)\n            image_wrists = np.stack(self.image_wrist_history)[None]\n            np.expand_dims(image_wrists, axis=0)\n            observation[\"image_wrist\"] = image_wrists\n        task = self.model.create_tasks(texts=[instruction])\n      # this returns *normalized* actions --> we need to unnormalize using the dataset statistics\n        norm_actions = self.model.sample_actions(observation, task, rng=jax.random.PRNGKey(0))\n        norm_actions = norm_actions[0]   # remove batch\n        actions = ("
        },
        {
            "comment": "This code calculates the normalized action by subtracting the mean and dividing by the standard deviation from the dataset's statistics, then creates an RT1Action object using the calculated action values.",
            "location": "\"/media/root/Prima/works/robo_transformers/docs/src/robo_transformers/models/octo/agent.py\":48-55",
            "content": "            norm_actions *self. model.dataset_statistics[\"bridge_dataset\"]['action']['std']\n            + self.model.dataset_statistics[\"bridge_dataset\"]['action']['mean']\n        )\n        action = np.array(actions[0]).squeeze()\n        #   action = np.sum(np.array(actions), axis = 0).squeeze()\n        rt1_action = RT1Action(world_vector=action[0:3], rotation_delta=np.array([action[5], action[4], action[3]]), gripper_closedness_action=np.array(action[6]))\n        return rt1_action"
        }
    ]
}